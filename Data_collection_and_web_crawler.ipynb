{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据集采集与网络爬虫：获取股票交易行情数据\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实习任务和要求\n",
    "\n",
    "1、访问\n",
    "\n",
    "http://quote.eastmoney.com/center/gridlist.html#hs_a_board\n",
    "\n",
    "获取“沪深A股”的交易行情数据。\n",
    "\n",
    "注意：在上图红框标注的“沪深A股”标签页的数据共有194页，要解决翻页的问题，\n",
    "\n",
    "要下载所有的数据，并保存数据到数据库（使用任何一种数据库）中。\n",
    "\n",
    "2、访问\n",
    "\n",
    "http://www.swsindex.com/idx0530.aspx#\n",
    "\n",
    "下载沪深A股“全部行业分类”数据。是一个Excel文件。\n",
    "\n",
    "把这个Excel文件的数据导入到数据库中。\n",
    "\n",
    "\n",
    "\n",
    "3、访问类似如下的网页\n",
    "\n",
    "http://data.eastmoney.com/zjlx/002157.html\n",
    "\n",
    "\n",
    "注意，上述链接中标为红色的是股票代码，它可以同第二步中的Excel文件中提取，或者从第一步中下载的到的数据中提取。\n",
    "\n",
    "要求：下载所有股票的历史资金流向数据，并保存在数据库中。\n",
    "\n",
    "4、根据以上下载的数据，做如下的数据分析。\n",
    "\n",
    "4.1、根据第二步中的行业分类，统计得出每个行业的资金流向数据。并用合适的可视化方式展现出来。\n",
    "\n",
    "4.2、根据上述采集的数据，试分析一个股票的资金流入性质的不同统计数据与股票涨跌之间有没有某种关系？\n",
    "\n",
    "4.3、自己设计和证券相关的一个问题，并下载数据进行分析。（必做，占30%的成绩）。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一、获取页面"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from  bs4 import BeautifulSoup\n",
    "import os\n",
    "import lxml\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#获取url下的页面内容，返回soup对象\n",
    "def get_page(url):\n",
    "    responce = requests.get(url)\n",
    "    soup = BeautifulSoup(responce.text,'lxml')\n",
    "    return soup\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二、解析数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analysis_soup(soup):\n",
    "    \"\"\"\n",
    "    传入一个suop对象，对其进行解析得到股票实时信息数据的字典列表\n",
    "    \"\"\"\n",
    "    #获取P标签下的数据\n",
    "    a=soup.find_all('p')\n",
    "    #类型转换\n",
    "    b = str(a)\n",
    "    #对字符串进行分割，去掉不需要的数据\"<p>jQuery112408123510576841297_1577064081282();</p>\"\n",
    "    c=b.split(\">\")\n",
    "    #得到json格式的str\n",
    "    d=c[1].split(\"<\")\n",
    "    #用json对数据进行解析\n",
    "    e = json.loads(d[0])\n",
    "    #得到data下的字典数据\n",
    "    f=e[\"data\"]\n",
    "\n",
    "    #得到列表g,存储股票信息的字典\n",
    "    g = f[\"diff\"]\n",
    "    return g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 三、获取所有数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shares_data(): \n",
    "    \"\"\"获取所有股票信息\"\"\"\n",
    "    shares_data_list= []\n",
    "    for i in range(1,195):\n",
    "        \n",
    "        t =time.time()\n",
    "        nowTime = lambda:int(round(t * 1000))           #毫秒级时间戳，基于lambda\n",
    "        #i是页面\n",
    "        url =\"\"\"http://39.push2.eastmoney.com/api/qt/clist/get?cb=&pn=\"\"\"+str(i)+\"\"\"\n",
    "        &pz=20&po=1&np=1&ut=bd1d9ddb04089700cf9c27f6f7426281&fltt=2&invt=2\n",
    "        &fid=f3&fs=m:0+t:6,m:0+t:13,m:0+t:80,m:1+t:2,m:1+t:23&\n",
    "        fields=f1,f2,f3,f4,f5,f6,f7,f8,f9,f10,f12,f13,f14,f15,f16,f17,f18,f20,f21,f23,f24,f25,f22,f11,f62,f128,f136,f115,f152\n",
    "        &_=1\"\"\"+str(nowTime)\n",
    "\n",
    "        #获取网页信息\n",
    "        soup =  get_page(url)\n",
    "        #获取每页的数据\n",
    "        shares_page_data = analysis_soup(soup)\n",
    "        shares_data_list[len(shares_data_list):len(shares_data_list)]= shares_page_data\n",
    "    return shares_data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "shares_data_list = get_shares_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3875"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(shares_data_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 四、数据库操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
